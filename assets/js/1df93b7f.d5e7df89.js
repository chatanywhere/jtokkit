"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[237],{3808:(t,e,n)=>{n.r(e),n.d(e,{default:()=>s});var o=n(7294),r=n(5096),a=n(9960);const i={intro:"intro_q4os",introText:"introText_PBmw",introSubtext:"introSubtext_AG2V",buttonIntro:"buttonIntro_tvxU",buttonIntroContainer:"buttonIntroContainer_Ez1V"};function s(){return o.createElement(r.Z,null,o.createElement("main",{className:i.intro},o.createElement("div",{className:"text--center"},o.createElement("div",{className:`padding--md text--bold ${i.introText}`},"JTokkit"),o.createElement("div",{className:`padding--md ${i.introSubtext}`},"A Java tokenizer library designed for use with OpenAI models"),o.createElement("div",{className:i.buttonIntroContainer},o.createElement(a.Z,{to:"/docs/getting-started",className:`button ${i.buttonIntro} button--lg`},"Get Started")))))}}}]);